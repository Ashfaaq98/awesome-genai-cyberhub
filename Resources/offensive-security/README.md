# 🚀 LLMs in Offensive Security (Red Teaming & Pentesting)

> A curated collection of Large Language Model (LLM) resources focused on **applications in offensive security, red teaming, and penetration testing (for research and advancing defenses)**.

Welcome to the **Offensive Security** section of Awesome GenAI CyberHub! This space is dedicated to exploring (from a research and defensive perspective) how LLMs are being utilized to augment and automate complex offensive cyber operations. This includes the development of AI agents capable of autonomous hacking and penetration testing, advanced techniques for social engineering and phishing generation, AI-assisted exploit crafting and zero-day vulnerability discovery, methods for simulating entire attack lifecycles, and tools for automating red team tasks. We also cover the responsible development of such offensive AI capabilities. The purpose is to understand these potential threats to build better defenses. Here, you'll find links to relevant articles, research papers, tools, datasets, and proof-of-concepts.

---

## ✅ Curated Resources


### 📜 Research Papers

* 📄 [From Sands to Mansions: Simulating Full Attack Chain with LLM-Organized Knowledge](https://arxiv.org/pdf/2407.16928) **[Paper]** 

* 📄 [VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative Framework (23 January 2025)](https://arxiv.org/pdf/2501.13411v1) **[Paper]** 

* 📄 [HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing (2 Dec 2024)](https://arxiv.org/pdf/2412.01778v1) **[Paper]** 

* 📄 [CIPHER: Cybersecurity Intelligent Penetration-Testing Helper for Ethical Researcher (26 October 2024)](https://www.mdpi.com/1424-8220/24/21/6878) **[Paper]** 

* [Responsible Development of Offensive AI (9 May 2024)](https://arxiv.org/pdf/2504.02701) **[Paper]**

* 📄 [ARTIFICIAL INTELLIGENCE AS THE NEW HACKER: DEVELOPING AGENTS FOR OFFENSIVE SECURITY (9 May 2024)](https://arxiv.org/pdf/2406.07561) **[Paper]** 

* 📄 [LLM Agents can Autonomously Hack Websites (16 Feb 2024)](https://arxiv.org/pdf/2402.06664v3) **[Paper]**

* 📄 [Lateral Phishing with Large Language Models: A Large Organization Comparative Study (March 25, 2025)](https://arxiv.org/html/2401.09727v2) **[Paper]**

* 📄 [Next-Generation Phishing: How LLM Agents Empower Cyber Attackers (21 Nov 2024)](https://arxiv.org/pdf/2411.13874) **[Paper]** 

* 📄 [Evaluating Large Language Models’ Capability to Launch Fully Automated Spear Phishing Campaigns: Validated on Human Subjects (30 NOV 2024)](https://arxiv.org/pdf/2412.00586) **[Paper]** 

* [When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs (03 Feb 2025)](https://arxiv.org/pdf/2410.14569v3) **[Paper]** - 


* 📄 [Evaluating Large Language Models’ Capability to Launch Fully Automated Spear Phishing Campaigns: Validated on Human Subjects ](https://arxiv.org/html/2412.00586v1) **[Paper]**  *(Published November/December 2024)*

### 📚 Articles & Blog Posts

* [LLM Agents can Autonomously Hack Websites (Daniel Kang on Medium)](https://medium.com/@danieldkang/llm-agents-can-autonomously-hack-websites-ab33fadb3062) **[Blog]** 

* [LLM-driven autonomous penetration testing (Gaya3 R. on Medium)](https://gaya3-r.medium.com/llm-driven-autonomous-penetration-testing-f4cb0566f386) **[Blog]** 

* [Building AI Agents to Solve Security Challenges (DevSec Blog)](https://devsec-blog.com/2024/12/building-ai-agents-to-solve-security-challenges/) **[Blog]** 

* [Measuring AI agents’ ability to exploit web applications (Daniel Kang on Medium)](https://medium.com/@danieldkang/measuring-ai-agents-ability-to-exploit-web-applications-ba4225aa281f) **[Blog]** 

* [Can Autonomous LLM Agents Exploit One Day Vulnerabilities? (Ionix Blog, Explaining arXiv:2404.08144)](https://www.ionix.io/blog/autonomous-llm-exploit-one-day-vulnerabilities-arxiv-2404-08144-explained/) **[Blog]**


* [The Future of Application Security: Integrating LLMs and AI Agents into Manual Workflows (Anshuman Bhartiya's Blog)](https://www.anshumanbhartiya.com/posts/the-future-of-appsec?trk=public_post_comment-text) **[Blog]**


* [From Naptime to Big Sleep: LLM Cyber Evaluations Don't Capture Real-World Risk (Google Project Zero Blog / arXiv:2502.00072v1)](https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html) **[Blog]** 


* [0day Discoveries (ZeroPath Blog)](https://zeropath.com/blog/0day-discoveries) **[Blog]**

* [How to build an offensive AI security agent (Anshuman Bhartiya's Blog)](https://www.anshumanbhartiya.com/posts/hackagent) **[Blog]** 

* [A ​low-cost hacking sidekick: Baby steps to using offensive AI agents (Bugcrowd Blog)](https://www.bugcrowd.com/blog/a-low-cost-hacking-sidekick-baby-steps-to-using-offensive-ai-agents/) **[Blog]**

* [Using AI for Offensive Security: Executive Report Summary (Cobalt.io Blog)](https://www.cobalt.io/blog/using-ai-for-offensive-security-report-summary) **[Blog]** 


* [Building an LLM-Based Attack Lifecycle With a Self-Guided Agent (Deep Instinct Blog)](https://www.deepinstinct.com/blog/beyond-flesh-and-code-building-an-llm-based-attack-lifecycle-with-a-self-guided-agent) **[Blog]** 

* [Google's Big Sleep: From Concept to Vulnerability Discovery (Cyber Magazine)](https://cybermagazine.com/articles/googles-big-sleep-from-concept-to-vulnerability-discovery) **[Article]** 

* [Building Your First Offensive Security MCP Server (nae-bo on Medium)](https://nae-bo.medium.com/building-your-first-offensive-security-mcp-server-dd655e258d5f) **[Blog]** 

* 📰 [AI-Powered Phishing Outperforms Elite Red Teams in 2025](https://hoxhunt.com/blog/ai-powered-phishing-vs-humans) **[Blog]**  *(Published April 2025)*

* 🧑‍🏫 [Corey White - The Frontier of Cybersecurity Defending Against AI Based Threats](../../assets/docs/Corey%20White%20-%20The%20Frontier%20of%20Cybersecurity%20Defending%20Against%20AI%20Based%20Threats.pdf) **[Slides]**


### 🛠️ Tools & Frameworks

* [🛠️ RamiGPT (M507/RamiGPT on GitHub)](https://github.com/M507/RamiGPT) **[Tool/GitHub]** - An AI-driven offensive security tool.


---

## Navigate Back

* [Back to Awesome GenAI CyberHub Main Page](../../README.md)